% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenify.R
\name{tokenize_col}
\alias{tokenize_col}
\title{turns a column of strings into a tokenized dataframe this returned dataframe will have two or three columns}
\usage{
tokenize_col(
  dat,
  ...,
  col_nm,
  row_name_nm = TOKENIZE_DEFAULT_ROW_NAME,
  token_type = glue::glue("{col_nm}"),
  tokenizer = tokenizer_basic
)
}
\arguments{
\item{dat}{dataframe}

\item{...}{passed to tokenizer}

\item{col_nm}{column that will be tokenized.}

\item{row_name_nm}{name of a return column that has the rownames in the original dataframe default row_name}

\item{token_type}{name of column that has tokens in return dataframe. Default appends '_type' onto token_col_nm}

\item{tokenizer}{function that tokenzes the column. Default  tidytext::unnest_tokens}
}
\description{
turns a column of strings into a tokenized dataframe this returned dataframe will have two or three columns
}
\examples{
dat_ceo <- readr::read_csv('https://tinyurl.com/2p8etjr6')
tokenize_col(dat = dat_ceo, col_nm = 'coname')
tokenize_col(dat = dat_ceo, col_nm = 'coname', token_type = 'company_name')

}
