% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenify.R
\name{keep_tokens}
\alias{keep_tokens}
\title{Given a dataframe of all tokens, object will return a dataframe of tokens that is a subset of the dataset}
\usage{
keep_tokens(
  tokens_all,
  min_token_u_prob = TOKEN_MIN_UPROB_DEFAULT,
  max_total_comparisons = TOKEN_MAX_COMPARE_DEFAULT,
  remove_n_comparisons_zero = TOKEN_REMOVE_ZERO_COMARE,
  ...
)
}
\arguments{
\item{tokens_all}{a dataframe normally from  t_dat$tokens_all}

\item{min_token_u_prob}{minimum u_prob to keep, can be NULL to not filter: Default TOKEN_MIN_UPROB_DEFAULT}

\item{max_total_comparisons}{maximum number of comparisons to allow it will pick tokens with the smallest number of n_comparisons first, NULL is also allowed to not filder : Default  25000000}

\item{remove_n_comparisons_zero}{Remove tokens that can not be included in comparisons: Default TRUE}

\item{...}{Ignored}
}
\description{
Given a dataframe of all tokens, object will return a dataframe of tokens that is a subset of the dataset
}
