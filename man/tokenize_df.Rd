% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenify.R
\name{tokenize_df}
\alias{tokenize_df}
\title{Tokenize a dataframe and multiple columns in the dataframe}
\usage{
tokenize_df(dat, ..., col_nms, token_types = col_nms)
}
\arguments{
\item{dat}{dataframe}

\item{...}{passed to tokenize_col}

\item{col_nms}{vector of string. These strings are column names in dat to tokenize. Default None}

\item{token_types}{vector of strings. these are the type of tokens for each token column}
}
\description{
Tokenize a dataframe and multiple columns in the dataframe
}
\examples{
temp_fn <- tempfile()
download.file("https://www150.statcan.gc.ca/n1/pub/37-26-0001/2021001/ODEF_v2.zip",temp_fn)
dat_odef <- readr::read_csv(unz(temp_fn, "ODEF_v2/ODEF_v2.csv"))
dat_odef |> tokenize_df(col_nms = c('Facility_Name','Facility_Type', 'Authority_Name', 'Full_Addr'), token_types = c('company_name', 'company_name', 'company_name', 'Address'))

}
