% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenify.R
\name{token_count}
\alias{token_count}
\title{Takes a dataframe with columns from cols and counts the unique ocurrances, returns a dataframe with counts.}
\usage{
token_count(dat_tokens, cols = c("token", "token_type"), .groups = "drop", ...)
}
\arguments{
\item{cols}{vector of column names. Default token, token_type}

\item{.groups}{passed to summarize. Default 'drop'}

\item{...}{not used}

\item{dat_token}{dataframe with columns in cols.}
}
\description{
Takes a dataframe with columns from cols and counts the unique ocurrances, returns a dataframe with counts.
}
\examples{

temp_fn <- tempfile()
download.file("https://www150.statcan.gc.ca/n1/pub/37-26-0001/2021001/ODEF_v2.zip",temp_fn)
dat_odef <- readr::read_csv(unz(temp_fn, "ODEF_v2/ODEF_v2.csv"))
toke_odef <- dat_odef |> tokenize_df(col_nms = c('Facility_Name','Facility_Type', 'Authority_Name', 'Full_Addr'), token_types = c('company_name', 'company_name', 'company_name', 'Address'))
toke_odef |> token_count()

}
