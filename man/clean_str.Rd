% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenify.R
\name{clean_str}
\alias{clean_str}
\title{replaces tokens, and cleans a string using regex stuff largely}
\usage{
clean_str(
  x,
  ...,
  token_type,
  rep = read_replacements_token_type(token_type),
  remove_accents = TRUE,
  remove_punctuation = TRUE,
  iconv_to = "ASCII//TRANSLIT",
  punc_remove_patern = "[^[:alnum:][:cntrl:][:space:]_]",
  punc_replace = " ",
  new_token_wrapper = " "
)
}
\arguments{
\item{x}{vector of strings}

\item{...}{ignored, used to ensure pass by keyword}

\item{token_type}{used to to try and load a default token replacement. no default}

\item{rep}{dataframe with three columns indicating what to replace. default  read_replacements_token_type(token_type)}

\item{remove_accents}{bool. Default = TRUE.}

\item{remove_punctuation}{bool. Default = TRUE.}

\item{iconv_to}{passed to iconv as the to parameter if remove_accents is TRUE. Default = 'ASCII//TRANSLIT'}

\item{punc_remove_patern}{string regex that finds punctuation to remove if remove_punctuation is TRUE. Default "[^[:alnum:][:cntrl:][:space:]_]"}

\item{punc_replace}{string replaces all punctuation if remove_punctuation is TRUE. default " ",}

\item{new_token_wrapper}{string. Placed on both sides of the new token. Default = " ".}
}
\description{
replaces tokens, and cleans a string using regex stuff largely
}
